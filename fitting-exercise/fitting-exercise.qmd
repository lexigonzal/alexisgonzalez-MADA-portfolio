---
title: "Model Fitting Exercise"
---

#Loading in the usual packages
```{r}
library(tidyverse)
library(tidymodels)
library(ggplot2)
```
#Load in the data
```{r}
data_path <- file.path("../fitting-exercise/data/Mavoglurant_A2121_nmpk.csv")
drug_data <- read.csv(data_path)

```
#Checking if my data loaded in properly
```{r}
str(drug_data)
summary(drug_data)
```
#Plotting DV by time and stratisfying by dose for each person
```{r}
ggplot(drug_data, aes(x = TIME, y = DV, group = ID, color = as.factor(DOSE))) +
  geom_line(alpha = 0.7) +
  labs(x = "TIME", y = "DV", color = "DOSE") +
  theme_minimal() +
  theme(legend.position = "top")
```
#Removing all entries with OCC=2
```{r}
drug_data2 <- drug_data %>%
  filter(OCC != 2)
```
#Removing time=0 and adding DV for each ID
```{r}
drug_data3 <- drug_data2 %>%
  filter(TIME != 0) %>%
  group_by(ID) %>%
  summarize(Y = sum(DV, na.rm = TRUE))
```
#Data frame where time=0
```{r}
time_zero <- drug_data2 %>%
  filter(TIME==0)

```
#Inner joining the data (maybe?)
```{r}
combined_data <- inner_join(drug_data3, time_zero, by = "ID")
```
#Filtering the data more by removing OCC and EVID and converting RACE and SEX into factor variables
```{r}
drug_data_final <- combined_data %>%
  select(-OCC,-EVID) %>%
  mutate(
    RACE = as.factor(RACE),
    SEX = as.factor(SEX)
  )

```
#Exploratory Analysis
#Summary tables
```{r}
summary_table <- drug_data_final %>%
  summarize(
    n = n(),  # Number of observations
    mean_Y = mean(Y, na.rm = TRUE),
    sd_Y = sd(Y, na.rm = TRUE),
    min_Y = min(Y, na.rm = TRUE),
    max_Y = max(Y, na.rm = TRUE)
  )
print(summary_table)
```

```{r}
summary_table <- drug_data_final %>%
  summarize(
    n = n(),  # Number of observations
    mean_WT = mean(WT, na.rm = TRUE),
    sd_WT = sd(WT, na.rm = TRUE),
    min_WT = min(WT, na.rm = TRUE),
    max_WT = max(WT, na.rm = TRUE)
  )
print(summary_table)

```

```{r}
summary_table <- drug_data_final %>%
  summarize(
    n = n(),  # Number of observations
    mean_HT = mean(HT, na.rm = TRUE),
    sd_HT = sd(HT, na.rm = TRUE),
    min_HT = min(HT, na.rm = TRUE),
    max_HT = max(HT, na.rm = TRUE)
  )
print(summary_table)
```

#Summary Figures
#####plotting WT vs HT in a scatter plot
```{r}
ggplot(drug_data_final, aes(x = WT, y = HT)) +
  geom_point(color = "blue", size = 3, alpha = 0.7) + 
  labs(title = "Scatter Plot of Weight vs Height",
       x = "Weight (kg)",
       y = "Height (cm)") +
  theme_minimal()
```
#Distribution of dose across ages
```{r}
ggplot(drug_data_final, aes(x = Y)) +
  geom_histogram(fill = "purple", bins = 15, alpha = 0.7) +
  facet_wrap(~ cut(AGE, breaks = seq(20, 80, by = 10))) +  # Group age into bins
  labs(title = "Histogram of total drug Y for Different Age Groups",
       x = "Dose",
       y = "Count") +
  theme_minimal()

```
#Distribution of Y by HT and WT
```{r}
ggplot(drug_data_final, aes(x = HT, y = Y)) +
  geom_point(color = "blue", alpha = 0.6) +  
  geom_smooth(method = "loess", color = "red", se = FALSE) +  
  labs(title = "Scatter Plot of Total Drug (Y) by Height",
       x = "Height",
       y = "Total Drug (Y)") +
  theme_minimal()
```
#WT
```{r}
ggplot(drug_data_final, aes(x = WT, y = Y)) +
  geom_point(color = "blue", alpha = 0.6) +  
  geom_smooth(method = "loess", color = "red", se = FALSE) +  
  labs(title = "Scatter Plot of Total Drug (Y) by Height",
       x = "Height",
       y = "Total Drug (Y)") +
  theme_minimal()
```
#Distribution of Y by Race
```{r}
ggplot(drug_data_final, aes(x = factor(RACE), y = Y)) +
  stat_summary(fun = mean, geom = "col", fill = "orange") +
  labs(title = "Average Total Drug (Y) by Race",
       x = "Race",
       y = "Mean Total Drug (Y)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```
#Y by Sex 
```{r}
ggplot(drug_data_final, aes(x = factor(SEX), y = Y)) +
  stat_summary(fun = mean, geom = "col", fill = "pink") +
  labs(title = "Average Total Drug (Y) by Sex",
       x = "Race",
       y = "Mean Total Drug (Y)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

### Now I will use tidymodels to fit a linear model to Y by Dose
#### First i will use parsnips package to specify the model that I want to use. Since there are continouos variables this will be a linear model
```{r}
lm_model <- linear_reg() %>%
  set_engine("lm")
```
#From here I can estimate the model using the fit function. I will be looking at Y ~ Dose x ID
```{r}
lm_fit <-
  lm_model %>%
  fit(Y ~ DOSE, data = drug_data_final)
lm_fit
```
#I can use tidy function to describe my model 
```{r}
tidy(lm_fit)
```


```{r}

# Define a linear regression model
lm_model <- linear_reg() %>% 
  set_engine("lm")

# Create a recipe (preprocessing steps, if any)
lm_recipe <- recipe(Y ~ DOSE, data = drug_data_final)

# Create a workflow
lm_workflow <- workflow() %>%
  add_model(lm_model) %>%
  add_recipe(lm_recipe)

# Fit the model
lm_fit <- lm_workflow %>% fit(data = drug_data_final)

```


```{r}
# Make predictions on test data
predictions <- predict(lm_fit, new_data = test_data) %>%
  bind_cols(test_data)  # Combine predictions with actual values

# Compute performance metrics
metrics <- predictions %>%
  metrics(truth = Y, estimate = .pred)

# Print results
metrics

```


#Now I will repeat the process but I will fit the model to outcome Y using all predictors
```{r}
lm_fit2 <-
  lm_model %>%
  fit(Y ~ DOSE * RATE * AGE * SEX * SEX * RACE * HT * WT, data=drug_data_final)
lm_fit2

```

```{r}
tidy(lm_fit2)
```
#R-squared and RMSE
```{r}
# Define a linear regression model
lm_model <- linear_reg() %>% 
  set_engine("lm")

# Create a recipe (preprocessing steps, if any)
lm_recipe2 <- recipe(Y ~ DOSE + RATE + AGE + SEX + RACE + HT + WT, data = drug_data_final)

# Create a workflow
lm_workflow2 <- workflow() %>%
  add_model(lm_model) %>%
  add_recipe(lm_recipe)

# Fit the model
lm_fit2 <- lm_workflow %>% fit(data = drug_data_final)

```


```{r}
# Make predictions on test data
predictions2 <- predict(lm_fit2, new_data = test_data) %>%
  bind_cols(test_data) 

# Compute performance metrics
metrics2 <- predictions2 %>%
  metrics(truth = Y, estimate = .pred)

# Print results
metrics2

```

#Logistic model requires a categorical variable, I dont know which is male or female but i will make sure this variable categorical
```{r}
drug_data_final$SEX <- as.factor(drug_data_final$SEX)

```

####Now I will repeat the process with a logistic model. starting with the parsnips package to specify my model

```{r}
log_model <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")
```
#Fitting the model
```{r}
log_fit <-
  log_model %>%
  fit(SEX ~ DOSE , data = drug_data_final)
log_fit
```
#Fitting the model the long way?
```{r}
logistic_mod <- logistic_reg() %>% 
  set_engine("glm") %>%  
  set_mode("classification")  

#Creating a recipe
data_recipe <- recipe(SEX ~ DOSE, data=drug_data_final) 
#Creating a workflow
logistic_workflow <- workflow() %>%
  add_model(logistic_mod) %>%
  add_recipe(data_recipe)
#fitting the model
logistic_fit <- logistic_workflow %>%
  fit(data = drug_data_final)
#checking to see if it worked 
tidy(logistic_fit)  # View model coefficients
glance(logistic_fit)  # View overall model performance

```
#Computing accuracy
```{r}
set.seed(1)
data_split <- initial_split(drug_data_final, prop = 0.8, strata = SEX)
train_data <- training(data_split)
test_data <- testing(data_split)

#adding the recipe and workflow
#Creating a recipe
data_recipe <- recipe(SEX ~ DOSE, data=drug_data_final) 
#Creating a workflow
logistic_workflow <- workflow() %>%
  add_model(logistic_mod) %>%
  add_recipe(data_recipe)
#fit the model to training data
logistic_fit <- logistic_workflow %>%
  fit(data = train_data)
#Making predictions on data
test_predictions <- logistic_fit %>%
  predict(new_data = test_data, type = "prob") %>%  # Get probabilities
  bind_cols(predict(logistic_fit, new_data = test_data)) %>%  # Get class predictions
  bind_cols(test_data)  # Add actual values
#computing accuracy
accuracy_result <- test_predictions %>%
  metrics(truth = SEX, estimate = .pred_class) %>%
  filter(.metric == "accuracy")

print(accuracy_result)

roc_auc_result <- test_predictions %>%
  roc_auc(truth = SEX, 1)  # Adjust `.pred_Male` based on levels in SEX

print(roc_auc_result)


```

#Fitting to all model
```{r}
logistic_mod2 <- logistic_reg() %>% 
  set_engine("glm") %>%  
  set_mode("classification")  
data_recipe2 <-recipe(SEX ~ DOSE * RATE * AGE * Y * RACE * HT * WT, data = drug_data_final)
logistic_workflow2 <- workflow() %>%
  add_model(logistc_mod2) %>%
  add_recipe(data_recipe2)
logisitic_fit2 <- logistic_workflow2 %>%
  fit(data = drug_data_final)
log_fit2 <-
  log_model %>%
  fit(SEX ~ DOSE * RATE * AGE * Y * RACE * HT * WT, data = drug_data_final)
log_fit2
```



#MODULE 10 STUFF
#Removing the RACE variable from the dataset

#setting seed
```{r}
rngseed=1234
```
#Removing variables 
```{r}
drugdata_new <- drug_data_final %>%
  select(Y,DOSE,AGE,SEX,WT,HT)
```
#Random sampling seed
```{r}
set.seed(rngseed)
```
#splitting the data 75% training
```{r}
data_split <- initial_split(drugdata_new, prop = 3/4)
train_data <- training(data_split)
test_data <-testing(data_split)
```

#Model fitting using dose only as a predictor
```{r}
# Define a linear regression model
lm_mod <- linear_reg() %>% 
  set_engine("lm")

# Create the model
lm_moddose <- lm_mod %>%
  fit(Y ~ DOSE, data=train_data)

```

#Model fitting using all as a predictor

```{r}
# Define a linear regression model
lm_mod <- linear_reg() %>% 
  set_engine("lm")
#Create model
lm_modall <- lm_mod %>%
  fit(Y ~ DOSE * AGE * SEX * WT * HT, data = train_data)
```

#Null model
```{r}
#Null model
null_model <- null_model(mode = "regression") %>%
  set_engine("parsnip") %>%
  fit(Y ~ 1, data= train_data)
```

#Computing predications lm_mod and lm_modall
```{r}
#predictions for dose, all, and null
predictsdose <- predict(lm_moddose, new_data = train_data)
predictall <-predict(lm_modall, new_data = train_data)
predictnull <- predict(null_model, new_data = train_data)
```
#Calculating RMSE & r-squared
```{r}
rmse_dose <- tibble(truth = train_data$Y, predicted = predictsdose$.pred) %>%
  metrics(truth = truth, estimate = predicted)
print(rmse_dose)
```

```{r}
rmse_all <- tibble(truth = train_data$Y, predicted = predictall$.pred) %>%
  metrics(truth = truth, estimate = predicted)
print(rmse_all)
```
```{r}
rmse_null <- tibble(truth = train_data$Y, predicted = predictnull$.pred) %>%
  metrics(truth = truth, estimate = predicted)
print(rmse_null)
```
#Model performance 2

#Setting a new seed for samplign
```{r}
set.seed(1234)
```
#10 fold CV
```{r}
folds <- vfold_cv(train_data, v=10)
folds
```
#Workflow for dose only model
```{r}
dose_wf <- workflow() %>%
  add_model(lm_mod) %>%
  add_formula(Y ~ DOSE)
set.seed(1111)
dose_fit_rs <- dose_wf %>%
  fit_resamples(folds)
```
#RMSE
```{r}
collect_metrics(dose_fit_rs)
```
#Workflow for all predictors
```{r}
all_wf <- workflow() %>%
  add_model(lm_mod) %>%
  add_formula(Y ~ DOSE * AGE * SEX * WT * HT)
set.seed(2222)
all_fit_rs <- all_wf %>%
  fit_resamples(folds)
```
```{r}
collect_metrics(all_fit_rs)
```

# This section added by Guozheng Yang

# Model predictions

The code below is to visualize model fitting from the null model, model 1, and model 2.

```{r}
# Null model: prediction on the train set
pred_model0_gz <- predict(null_model, train_data) %>%
  bind_cols(train_data["Y"])
colnames(pred_model0_gz) <- c("pred", "Y")

# Model 1: prediction on the train set
pred_model1_gz <- predict(lm_moddose, train_data) %>%
  bind_cols(train_data["Y"])
colnames(pred_model1_gz) <- c("pred", "Y")

# Model 2: prediction on the train set
pred_model2_gz <- predict(lm_modall, train_data) %>%
  bind_cols(train_data["Y"])
colnames(pred_model2_gz) <- c("pred", "Y")

# Combine the three data sets and make a plot
comb_gz <- rbind(pred_model0_gz, pred_model1_gz, pred_model2_gz) %>%
  mutate(Model=c(rep("Null model", nrow(pred_model0_gz)), 
                 rep("Model 1", nrow(pred_model1_gz)), 
                 rep("Model 2", nrow(pred_model2_gz)))) %>%
  ggplot(aes(x=Y, y=pred, fill=Model))+
  geom_point(size=4, stroke=1, alpha=0.7, shape=21)+
  geom_abline(intercept=0, slope=1, linetype="dashed", color="black", linewidth=2)+
  scale_fill_manual(name="", values=c("dodgerblue1","palevioletred1","darkorange"))+
  scale_x_continuous(limits=c(0, 5000))+
  scale_y_continuous(limits=c(0, 5000))+
  labs(x="Observed value", y="Predicted value")+
  theme_bw()+
  theme(axis.title.x=element_text(size=25,color="black",margin=margin(t=15),face="bold"),
        axis.title.y=element_text(size=25,color="black",margin=margin(r=15),face="bold"),
        axis.text.x=element_text(color="black",size=20,vjust=0),
        axis.text.y=element_text(color="black",size=20,hjust=1), 
        legend.position="top",
        legend.title=element_text(size=20), 
        legend.text=element_text(size=18,vjust=0))
comb_gz
```

As shown, the predictions from the null model is a horizontal line, since this model only predicts the mean value of the response. The predictions from model 1 are three horizontal lines, since this model only has *DOSE* as the predictor which only has three possible values.

Now I'm making a residual plot for model 2. 

```{r}
# Residual plot for model 2
pred_model2_res_gz <- pred_model2_gz %>%
  mutate(res=pred-Y) %>%
  ggplot(aes(x=pred, y=res))+
  geom_point(size=4, stroke=1, alpha=0.7, shape=21, fill="firebrick3")+
  geom_abline(intercept=0, slope=0, linetype="dashed", color="black", linewidth=2)+
  scale_x_continuous(limits=c(0, 5000))+
  scale_y_continuous(limits=c(-2000, 2000))+
  labs(x="Predicted value", y="Residual")+
  theme_bw()+
  theme(axis.title.x=element_text(size=25,color="black",margin=margin(t=15),face="bold"),
        axis.title.y=element_text(size=25,color="black",margin=margin(r=15),face="bold"),
        axis.text.x=element_text(color="black",size=20,vjust=0),
        axis.text.y=element_text(color="black",size=20,hjust=1))
pred_model2_res_gz
```

As shown, despite some points with relatively small residuals, the points randomly distribute around y=0. This denote the generally good performance of model 2.

# Model predictions and uncertainty

Now I want to run a bootstrap to evaluate model 2. The code is shown below. 

```{r}
library(rsample)
# Set seed
set.seed(rngseed)

# Bootstrap: 100
dat_bs <- bootstraps(train_data, times=100)

# Model setting
model2_spec <- linear_reg() %>% set_engine("lm")

# Fit model 2 on 100 bootstraps and store the predictions
pred_bs <- matrix(NA, nrow=nrow(dat_bs), ncol=nrow(train_data))
for (i in seq_len(nrow(dat_bs))){
  fit_i <- fit(model2_spec, Y ~ ., analysis(dat_bs$splits[[i]]))
  preds_i <- predict(fit_i, new_data=train_data)$.pred
  pred_bs[i,] <- preds_i
}

# Calculate 95% CIs
preds <- pred_bs |> apply(2, quantile,  c(0.025, 0.5, 0.975)) |>  t()

# Make a plot to show the estimates
plot_est_gz <- train_data %>%
  mutate(point_est=pred_model2_gz$pred,
         median=preds[,2],
         lower=preds[,1],
         upper=preds[,3]) %>%
  ggplot(aes(x=Y))+
  geom_abline(intercept=0, slope=1, linetype="dashed", color="black", linewidth=1)+
  geom_point(aes(y=point_est), color="gray20", size=2, shape=16, alpha=.8)+ 
  geom_point(aes(y=median), color="firebrick2", size=2, shape=16, alpha=.8)+
  geom_errorbar(aes(ymin=lower, ymax=upper), width=.2, color="palevioletred2", alpha=.8)+
  labs(x="Observed value", y="Predicted value")+
  scale_x_continuous(limits=c(0, 5000))+
  scale_y_continuous(limits=c(0, 5000))+
  theme_bw()+
  theme(axis.title.x=element_text(size=25,color="black",margin=margin(t=15),face="bold"),
        axis.title.y=element_text(size=25,color="black",margin=margin(r=15),face="bold"),
        axis.text.x=element_text(color="black",size=20,vjust=0),
        axis.text.y=element_text(color="black",size=20,hjust=1))
plot_est_gz
```

According to the output, the fitting results from bootstrapping are generally consistent with only fitting model 2 on the train set. Almost all the CIs (red) can cover the point predictions (black). From a big picture, the data points are distributed around the diagonal, which means the predicted values are close to the observed values. To this point, we can conclude the good performance of model 2.










